{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b00949-6d1e-4af1-8bcc-d54e7594c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment QC — Global Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>mv.fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sequences_total</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_same_length</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique_lengths</td>\n",
       "      <td>[0, 15893, 15894]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_length</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max_length</td>\n",
       "      <td>15894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with_gaps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>with_non_ATGC</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>observed_chars</td>\n",
       "      <td>ACGHKMNRSTWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kept_after_filters</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dropped_after_filters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>filters_min_len</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>filters_max_len</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>filters_min_gap_frac</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>filters_max_gap_frac</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metric              value\n",
       "0                    file              mv.fa\n",
       "1         sequences_total                226\n",
       "2         all_same_length              False\n",
       "3          unique_lengths  [0, 15893, 15894]\n",
       "4              min_length                  0\n",
       "5              max_length              15894\n",
       "6               with_gaps                  0\n",
       "7           with_non_ATGC                207\n",
       "8          observed_chars       ACGHKMNRSTWY\n",
       "9      kept_after_filters                226\n",
       "10  dropped_after_filters                  0\n",
       "11        filters_min_len               None\n",
       "12        filters_max_len               None\n",
       "13   filters_min_gap_frac               None\n",
       "14   filters_max_gap_frac               None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alignment QC — Per-sequence (with keep/drop flags)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>length</th>\n",
       "      <th>gap_count</th>\n",
       "      <th>gap_fraction</th>\n",
       "      <th>non_ATGC_count</th>\n",
       "      <th>non_ATGC_fraction</th>\n",
       "      <th>non_ATGC_chars</th>\n",
       "      <th>only_ATGC_and_gaps</th>\n",
       "      <th>keep</th>\n",
       "      <th>drop_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR30155677</td>\n",
       "      <td>15894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR30155678</td>\n",
       "      <td>15894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR30155679</td>\n",
       "      <td>15894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>N,Y</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR30155680</td>\n",
       "      <td>15894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>N,R,Y</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR30155681</td>\n",
       "      <td>15894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2312</td>\n",
       "      <td>0.145464</td>\n",
       "      <td>N,S</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>SRR25426232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>SRR25426246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>SRR25426257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>SRR25426267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>SRR25426268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence_id  length  gap_count  gap_fraction  non_ATGC_count  \\\n",
       "0    SRR30155677   15894          0           0.0               0   \n",
       "1    SRR30155678   15894          0           0.0               3   \n",
       "2    SRR30155679   15894          0           0.0              13   \n",
       "3    SRR30155680   15894          0           0.0              13   \n",
       "4    SRR30155681   15894          0           0.0            2312   \n",
       "..           ...     ...        ...           ...             ...   \n",
       "221  SRR25426232       0          0           0.0               0   \n",
       "222  SRR25426246       0          0           0.0               0   \n",
       "223  SRR25426257       0          0           0.0               0   \n",
       "224  SRR25426267       0          0           0.0               0   \n",
       "225  SRR25426268       0          0           0.0               0   \n",
       "\n",
       "     non_ATGC_fraction non_ATGC_chars  only_ATGC_and_gaps  keep drop_reason  \n",
       "0             0.000000                               True  True              \n",
       "1             0.000189              N               False  True              \n",
       "2             0.000818            N,Y               False  True              \n",
       "3             0.000818          N,R,Y               False  True              \n",
       "4             0.145464            N,S               False  True              \n",
       "..                 ...            ...                 ...   ...         ...  \n",
       "221           0.000000                               True  True              \n",
       "222           0.000000                               True  True              \n",
       "223           0.000000                               True  True              \n",
       "224           0.000000                               True  True              \n",
       "225           0.000000                               True  True              \n",
       "\n",
       "[226 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# ========= CONFIGURE HERE =========\n",
    "FASTA_PATH = Path(\"./mv.fa\")  # <- change to your file\n",
    "\n",
    "# Filtering thresholds (set to None to disable that bound)\n",
    "MIN_LEN: Optional[int] = None        # drop sequences with length < MIN_LEN\n",
    "MAX_LEN: Optional[int] = None        # drop sequences with length > MAX_LEN\n",
    "MIN_GAP_FRAC: Optional[float] = None # drop if gap_fraction < MIN_GAP_FRAC\n",
    "MAX_GAP_FRAC: Optional[float] = None # drop if gap_fraction > MAX_GAP_FRAC\n",
    "\n",
    "# Optional: also write CSVs (set to True to save)\n",
    "SAVE_FILES = False\n",
    "OUT_DIR = FASTA_PATH.parent\n",
    "# ==================================\n",
    "\n",
    "def read_fasta(path: Path):\n",
    "    \"\"\"Yield (header, sequence) for each entry in a FASTA file.\"\"\"\n",
    "    header = None\n",
    "    seq_chunks: List[str] = []\n",
    "    with open(path, \"r\") as fh:\n",
    "        for raw in fh:\n",
    "            line = raw.rstrip(\"\\r\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None:\n",
    "                    yield header, \"\".join(seq_chunks)\n",
    "                header = line[1:].strip()\n",
    "                seq_chunks = []\n",
    "            else:\n",
    "                seq_chunks.append(line.strip())\n",
    "    if header is not None:\n",
    "        yield header, \"\".join(seq_chunks)\n",
    "\n",
    "def compute_metrics(path: Path) -> pd.DataFrame:\n",
    "    rows: List[Dict] = []\n",
    "    global_chars = set()\n",
    "    for sid, seq in read_fasta(path):\n",
    "        s = seq.upper()\n",
    "        global_chars.update(s)\n",
    "        length = len(s)\n",
    "        gap_count = s.count(\"-\")\n",
    "        non_atgc_count = sum(ch not in {\"A\",\"C\",\"G\",\"T\",\"-\"} for ch in s)\n",
    "        non_atgc_chars = sorted({ch for ch in s if ch not in {\"A\",\"C\",\"G\",\"T\",\"-\"}})\n",
    "        rows.append({\n",
    "            \"sequence_id\": sid,\n",
    "            \"length\": length,\n",
    "            \"gap_count\": gap_count,\n",
    "            \"gap_fraction\": (gap_count / length) if length else 0.0,\n",
    "            \"non_ATGC_count\": non_atgc_count,\n",
    "            \"non_ATGC_fraction\": (non_atgc_count / length) if length else 0.0,\n",
    "            \"non_ATGC_chars\": \",\".join(non_atgc_chars),\n",
    "            \"only_ATGC_and_gaps\": (non_atgc_count == 0),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.attrs[\"observed_chars\"] = \"\".join(sorted(global_chars))\n",
    "    return df\n",
    "\n",
    "def apply_filters(df: pd.DataFrame,\n",
    "                  min_len: Optional[int],\n",
    "                  max_len: Optional[int],\n",
    "                  min_gap_frac: Optional[float],\n",
    "                  max_gap_frac: Optional[float]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    keep = pd.Series(True, index=df.index)\n",
    "    reasons: List[str] = []\n",
    "\n",
    "    # length filters\n",
    "    if min_len is not None:\n",
    "        keep &= df[\"length\"] >= min_len\n",
    "    if max_len is not None:\n",
    "        keep &= df[\"length\"] <= max_len\n",
    "\n",
    "    # gap filters\n",
    "    if min_gap_frac is not None:\n",
    "        keep &= df[\"gap_fraction\"] >= min_gap_frac\n",
    "    if max_gap_frac is not None:\n",
    "        keep &= df[\"gap_fraction\"] <= max_gap_frac\n",
    "\n",
    "    # per-row reasons\n",
    "    dr = []\n",
    "    for _, r in df.iterrows():\n",
    "        row_reasons = []\n",
    "        if (min_len is not None) and (r[\"length\"] < min_len): row_reasons.append(f\"len<{min_len}\")\n",
    "        if (max_len is not None) and (r[\"length\"] > max_len): row_reasons.append(f\"len>{max_len}\")\n",
    "        if (min_gap_frac is not None) and (r[\"gap_fraction\"] < min_gap_frac): row_reasons.append(f\"gap_frac<{min_gap_frac}\")\n",
    "        if (max_gap_frac is not None) and (r[\"gap_fraction\"] > max_gap_frac): row_reasons.append(f\"gap_frac>{max_gap_frac}\")\n",
    "        dr.append(\",\".join(row_reasons))\n",
    "    df[\"keep\"] = keep\n",
    "    df[\"drop_reason\"] = dr\n",
    "    return df\n",
    "\n",
    "def global_summary(df: pd.DataFrame, filt: pd.DataFrame, fasta_path: Path,\n",
    "                   min_len, max_len, min_gap_frac, max_gap_frac) -> pd.DataFrame:\n",
    "    unique_lengths = sorted(df[\"length\"].unique().tolist())\n",
    "    all_same_length = (len(unique_lengths) == 1)\n",
    "    obs_chars = df.attrs.get(\"observed_chars\", \"\")\n",
    "    summary_rows = [\n",
    "        {\"metric\": \"file\", \"value\": fasta_path.name},\n",
    "        {\"metric\": \"sequences_total\", \"value\": int(len(df))},\n",
    "        {\"metric\": \"all_same_length\", \"value\": bool(all_same_length)},\n",
    "        {\"metric\": \"unique_lengths\", \"value\": unique_lengths[:10] + ([\"...\"] if len(unique_lengths) > 10 else [])},\n",
    "        {\"metric\": \"min_length\", \"value\": int(df[\"length\"].min()) if len(df) else None},\n",
    "        {\"metric\": \"max_length\", \"value\": int(df[\"length\"].max()) if len(df) else None},\n",
    "        {\"metric\": \"with_gaps\", \"value\": int((df[\"gap_count\"] > 0).sum())},\n",
    "        {\"metric\": \"with_non_ATGC\", \"value\": int((df[\"non_ATGC_count\"] > 0).sum())},\n",
    "        {\"metric\": \"observed_chars\", \"value\": obs_chars},\n",
    "        {\"metric\": \"kept_after_filters\", \"value\": int(filt[\"keep\"].sum())},\n",
    "        {\"metric\": \"dropped_after_filters\", \"value\": int((~filt[\"keep\"]).sum())},\n",
    "        {\"metric\": \"filters_min_len\", \"value\": min_len},\n",
    "        {\"metric\": \"filters_max_len\", \"value\": max_len},\n",
    "        {\"metric\": \"filters_min_gap_frac\", \"value\": min_gap_frac},\n",
    "        {\"metric\": \"filters_max_gap_frac\", \"value\": max_gap_frac},\n",
    "    ]\n",
    "    return pd.DataFrame(summary_rows)\n",
    "\n",
    "# ---- Run QC ----\n",
    "df_metrics = compute_metrics(FASTA_PATH)\n",
    "df_filtered = apply_filters(df_metrics, MIN_LEN, MAX_LEN, MIN_GAP_FRAC, MAX_GAP_FRAC)\n",
    "summary_df = global_summary(df_metrics, df_filtered, FASTA_PATH,\n",
    "                            MIN_LEN, MAX_LEN, MIN_GAP_FRAC, MAX_GAP_FRAC)\n",
    "\n",
    "# Show tables inline\n",
    "print(\"Alignment QC — Global Summary\")\n",
    "display(summary_df)\n",
    "\n",
    "print(\"\\nAlignment QC — Per-sequence (with keep/drop flags)\")\n",
    "display(df_filtered.sort_values([\"keep\", \"length\"], ascending=[False, False]).reset_index(drop=True))\n",
    "\n",
    "# Optional CSVs\n",
    "if SAVE_FILES:\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    summary_df.to_csv(OUT_DIR / \"alignment_qc_summary.csv\", index=False)\n",
    "    df_filtered.to_csv(OUT_DIR / \"alignment_qc_per_sequence.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6f2f14-d723-4624-9449-74932e831674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        length\n",
       "length        \n",
       "0            9\n",
       "15893        2\n",
       "15894      215"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.groupby('length').agg({'length':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cafc2980-df90-4a08-bb01-4699782472bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Filter] GenBank expected length = 15894\n",
      "[Filter] Input sequences: 226\n",
      "[Filter] Kept: 164\n",
      "[Filter] Dropped: 62\n",
      "[Filter] Dropped (id  observed_len  expected_len  reasons) — first 20:\n",
      "  SRR30155681\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155687\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155690\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155695\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155708\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155713\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155720\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155721\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155727\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155731\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155732\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155736\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155738\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155739\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155740\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155743\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155746\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155748\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155749\t15894\t15894\ttoo_many_N(>100)\n",
      "  SRR30155755\t15894\t15894\ttoo_many_N(>100)\n",
      "  ... (42 more)\n",
      "[Filter] Report written: /home/anton/git/overlapTools/msa/_filter_report.tsv\n",
      "[Filter] Filtered MSA written: /home/anton/git/overlapTools/msa/mv.len15894.filtered.fa\n",
      "Wrote 8 feature-alignments to /home/anton/git/overlapTools/msa\n",
      "Index: /home/anton/git/overlapTools/msa/_index.tsv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Extract gene/CDS-aligned FASTAs from a multiple sequence alignment (MSA)\n",
    "using coordinates from NC_001498.1 (Measles virus) GenBank.\n",
    "\n",
    "Enhancements:\n",
    "- Keep ONLY sequences whose raw FASTA length equals the GenBank sequence length.\n",
    "- Optionally drop sequences with > MAX_N_COUNT ambiguous 'N' bases.\n",
    "- Optionally trim trailing stop codon from CDS slices (based on the reference CDS).\n",
    "\n",
    "Outputs:\n",
    "- One FASTA per feature in OUTPUT_DIR\n",
    "- _index.tsv manifest\n",
    "- _filter_report.tsv (dropped sequences + reasons)\n",
    "- filtered MSA snapshot (optional)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Third-party\n",
    "try:\n",
    "    from Bio import SeqIO, Entrez\n",
    "    from Bio.SeqFeature import CompoundLocation\n",
    "except Exception:\n",
    "    SeqIO = None\n",
    "    Entrez = None\n",
    "    CompoundLocation = None\n",
    "\n",
    "# --------------------- CONFIG ---------------------\n",
    "ACCESSION = \"NC_001498.1\"\n",
    "MSA_PATH = Path(\"/home/anton/git/overlapTools/mv.fa\")    # <- change if needed\n",
    "OUTPUT_DIR = Path(\"/home/anton/git/overlapTools/msa\")\n",
    "FEATURE_LEVEL = \"CDS\"                                    # \"gene\" or \"CDS\"\n",
    "REVCOMP_NEG_STRAND = True                                 # produce coding orientation on - strand\n",
    "\n",
    "# NCBI Entrez (if fetching online)\n",
    "NCBI_EMAIL = \"anton@nekrut.org\"                           # required by NCBI\n",
    "NCBI_API_KEY = None                                       # optional\n",
    "LOCAL_GENBANK: Optional[Path] = None                      # e.g. Path(\"/path/NC_001498.1.gb\")\n",
    "\n",
    "# Filtering & export options\n",
    "WRITE_FILTERED_MSA = True\n",
    "MAX_N_COUNT: Optional[int] = 100  # e.g. 100 -> drop sequences with >100 Ns; set None to disable\n",
    "TRIM_TRAILING_STOP: bool = True    # when FEATURE_LEVEL == \"CDS\" and reference CDS ends with stop, trim last 3 bases\n",
    "\n",
    "STOP_CODONS = {\"TAA\", \"TAG\", \"TGA\"}\n",
    "\n",
    "# --------------------- Helpers ---------------------\n",
    "@dataclass\n",
    "class FeatureSlice:\n",
    "    name: str\n",
    "    kind: str            # 'gene' or 'CDS'\n",
    "    strand: int          # +1 / -1 / 0\n",
    "    intervals: List[Tuple[int, int]]  # 1-based inclusive intervals [(start, end), ...]\n",
    "    qualifiers: Dict[str, List[str]]\n",
    "\n",
    "def read_fasta(path: Path) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Read a FASTA file into a list of (id, seqstr).\"\"\"\n",
    "    ids, seqs = [], []\n",
    "    cur_id, cur = None, []\n",
    "    with open(path, \"r\") as fh:\n",
    "        for line in fh:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if cur_id is not None:\n",
    "                    ids.append(cur_id)\n",
    "                    seqs.append(\"\".join(cur))\n",
    "                cur_id = line[1:].strip()\n",
    "                cur = []\n",
    "            else:\n",
    "                cur.append(line)\n",
    "    if cur_id is not None:\n",
    "        ids.append(cur_id)\n",
    "        seqs.append(\"\".join(cur))\n",
    "    return list(zip(ids, seqs))\n",
    "\n",
    "def find_reference_row(msa: List[Tuple[str, str]], accession_substr: str = ACCESSION) -> Optional[int]:\n",
    "    for i, (sid, _) in enumerate(msa):\n",
    "        if accession_substr in sid:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def build_pos_to_col_map_from_reference(ref_seq: str) -> Dict[int, int]:\n",
    "    \"\"\"Map ungapped reference genomic positions (1-based) → alignment columns (0-based).\"\"\"\n",
    "    pos_to_col, pos = {}, 0\n",
    "    for col, nt in enumerate(ref_seq):\n",
    "        if nt != \"-\":\n",
    "            pos += 1\n",
    "            pos_to_col[pos] = col\n",
    "    return pos_to_col\n",
    "\n",
    "def build_pos_to_col_map_identity(length: int) -> Dict[int, int]:\n",
    "    \"\"\"Identity mapping: assumes ungapped alignment and genome length == alignment length.\"\"\"\n",
    "    return {i: (i - 1) for i in range(1, length + 1)}\n",
    "\n",
    "def alignment_has_any_gaps(msa: List[Tuple[str, str]]) -> bool:\n",
    "    return any(\"-\" in s for _, s in msa)\n",
    "\n",
    "def fetch_or_read_genbank(accession: str, local_file: Optional[Path], email: Optional[str], api_key: Optional[str]):\n",
    "    if SeqIO is None:\n",
    "        raise RuntimeError(\"Biopython is required (pip install biopython) to parse GenBank.\")\n",
    "    if local_file is not None:\n",
    "        with open(local_file, \"r\") as fh:\n",
    "            return SeqIO.read(fh, \"genbank\")\n",
    "    if Entrez is None:\n",
    "        raise RuntimeError(\"Biopython Entrez is required to fetch GenBank from NCBI (pip install biopython).\")\n",
    "    if not email:\n",
    "        raise RuntimeError(\"Please set NCBI_EMAIL with your email to use NCBI Entrez.\")\n",
    "    Entrez.email = email\n",
    "    if api_key:\n",
    "        Entrez.api_key = api_key\n",
    "    with Entrez.efetch(db=\"nuccore\", id=accession, rettype=\"gbwithparts\", retmode=\"text\") as handle:\n",
    "        return SeqIO.read(handle, \"genbank\")\n",
    "\n",
    "def extract_features(record, level: str = \"gene\") -> List[FeatureSlice]:\n",
    "    \"\"\"Extract 'gene' or 'CDS' features as FeatureSlice objects.\"\"\"\n",
    "    if level not in {\"gene\", \"CDS\"}:\n",
    "        raise ValueError(\"level must be 'gene' or 'CDS'\")\n",
    "    feats: List[FeatureSlice] = []\n",
    "    for feat in record.features:\n",
    "        if feat.type != level:\n",
    "            continue\n",
    "\n",
    "        def loc_to_intervals(loc) -> List[Tuple[int, int]]:\n",
    "            if CompoundLocation is not None and isinstance(loc, CompoundLocation):\n",
    "                parts = []\n",
    "                for p in loc.parts:\n",
    "                    parts.append((int(p.start) + 1, int(p.end)))  # to 1-based inclusive\n",
    "                return parts\n",
    "            else:\n",
    "                return [(int(loc.start) + 1, int(loc.end))]\n",
    "\n",
    "        intervals = loc_to_intervals(feat.location)\n",
    "        strand = int(feat.location.strand or 0)\n",
    "        qualifiers = {k: v for k, v in feat.qualifiers.items()}\n",
    "        name = None\n",
    "        for key in (\"gene\", \"gene_synonym\", \"product\", \"note\", \"locus_tag\"):\n",
    "            if key in feat.qualifiers:\n",
    "                name = feat.qualifiers[key][0]\n",
    "                break\n",
    "        if not name:\n",
    "            start, end = intervals[0][0], intervals[-1][1]\n",
    "            name = f\"{level}_at_{start}_{end}\"\n",
    "        feats.append(FeatureSlice(name=name, kind=level, strand=strand, intervals=intervals, qualifiers=qualifiers))\n",
    "    return feats\n",
    "\n",
    "def sanitize_name(name: str) -> str:\n",
    "    name = re.sub(r\"\\s+\", \"_\", name)\n",
    "    name = re.sub(r\"[^A-Za-z0-9_.+-]\", \"_\", name)\n",
    "    return name\n",
    "\n",
    "def collect_columns_for_feature(pos_to_col: Dict[int, int], feature: FeatureSlice, revcomp_neg: bool) -> List[int]:\n",
    "    cols: List[int] = []\n",
    "    parts = feature.intervals\n",
    "    if feature.strand == -1 and revcomp_neg:\n",
    "        parts = list(reversed(parts))\n",
    "    for (start, end) in parts:\n",
    "        if start > end:\n",
    "            start, end = end, start\n",
    "        for pos in range(start, end + 1):\n",
    "            if pos not in pos_to_col:\n",
    "                raise KeyError(\n",
    "                    f\"Genomic position {pos} not present in mapping. \"\n",
    "                    f\"Include a reference row ({ACCESSION}) or use an ungapped alignment.\"\n",
    "                )\n",
    "            cols.append(pos_to_col[pos])\n",
    "    if feature.strand == -1 and revcomp_neg:\n",
    "        cols = cols[::-1]\n",
    "    return cols\n",
    "\n",
    "def _revcomp(seq: str) -> str:\n",
    "    comp = str.maketrans(\"ACGTUacgtu\", \"TGCAAtgcaa\")\n",
    "    return \"\".join('-' if ch == '-' else ch.translate(comp) for ch in seq[::-1])\n",
    "\n",
    "def feature_ref_coding_seq(record, feature: FeatureSlice, revcomp_neg: bool) -> str:\n",
    "    \"\"\"Get the reference coding sequence for a feature in coding orientation.\"\"\"\n",
    "    parts = feature.intervals\n",
    "    if feature.strand == -1 and revcomp_neg:\n",
    "        parts = list(reversed(parts))\n",
    "    ref = \"\".join(str(record.seq[s-1:e]) for s, e in parts).upper()\n",
    "    if feature.strand == -1 and revcomp_neg:\n",
    "        ref = _revcomp(ref).replace(\"-\", \"\")\n",
    "    return ref.replace(\"-\", \"\")\n",
    "\n",
    "def slice_alignment_columns(msa: List[Tuple[str, str]], columns: List[int],\n",
    "                            feature: FeatureSlice, revcomp_neg: bool) -> List[Tuple[str, str]]:\n",
    "    comp = str.maketrans(\"ACGTUacgtu\", \"TGCAAtgcaa\")\n",
    "    out = []\n",
    "    for sid, seq in msa:\n",
    "        subseq = ''.join(seq[c] for c in columns)\n",
    "        if feature.strand == -1 and revcomp_neg:\n",
    "            subseq = ''.join('-' if ch == '-' else ch.translate(comp) for ch in subseq[::-1])\n",
    "        out.append((sid, subseq))\n",
    "    return out\n",
    "\n",
    "def write_fasta(records: List[Tuple[str, str]], path: Path, header_suffix: str = \"\") -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\") as fh:\n",
    "        for sid, s in records:\n",
    "            header = f\"{sid} {header_suffix}\".strip()\n",
    "            fh.write(f\">{header}\\n\")\n",
    "            for i in range(0, len(s), 80):\n",
    "                fh.write(s[i:i+80] + \"\\n\")\n",
    "\n",
    "def write_simple_fasta(records: List[Tuple[str, str]], path: Path) -> None:\n",
    "    \"\"\"Write a simple FASTA (no suffixes), for the filtered MSA snapshot.\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\") as fh:\n",
    "        for sid, s in records:\n",
    "            fh.write(f\">{sid}\\n\")\n",
    "            for i in range(0, len(s), 80):\n",
    "                fh.write(s[i:i+80] + \"\\n\")\n",
    "\n",
    "# --------------------- Main ---------------------\n",
    "def main(\n",
    "    msa_path: Path = MSA_PATH,\n",
    "    feature_level: str = FEATURE_LEVEL,\n",
    "    output_dir: Path = OUTPUT_DIR,\n",
    "    accession: str = ACCESSION,\n",
    "    local_genbank: Optional[Path] = LOCAL_GENBANK,\n",
    "    email: Optional[str] = NCBI_EMAIL,\n",
    "    api_key: Optional[str] = NCBI_API_KEY,\n",
    "    revcomp_neg: bool = REVCOMP_NEG_STRAND,\n",
    "):\n",
    "    # Fetch GenBank to learn expected genome length\n",
    "    record = fetch_or_read_genbank(accession, local_file=local_genbank, email=email, api_key=api_key)\n",
    "    expected_len = len(record.seq)\n",
    "\n",
    "    # Read MSA, then filter by exact length and by N-count (if configured)\n",
    "    msa_all = read_fasta(msa_path)\n",
    "    kept: List[Tuple[str, str]] = []\n",
    "    filtered_out: List[Tuple[str, int, int, str]] = []  # (id, observed_len, expected_len, reasons)\n",
    "\n",
    "    for sid, seq in msa_all:\n",
    "        reasons = []\n",
    "        obs_len = len(seq)\n",
    "        if obs_len != expected_len:\n",
    "            reasons.append(\"length_mismatch\")\n",
    "        if MAX_N_COUNT is not None and seq.upper().count(\"N\") > MAX_N_COUNT:\n",
    "            reasons.append(f\"too_many_N(>{MAX_N_COUNT})\")\n",
    "        if reasons:\n",
    "            filtered_out.append((sid, obs_len, expected_len, \",\".join(reasons)))\n",
    "        else:\n",
    "            kept.append((sid, seq))\n",
    "\n",
    "    # Report filtering\n",
    "    print(f\"[Filter] GenBank expected length = {expected_len}\")\n",
    "    print(f\"[Filter] Input sequences: {len(msa_all)}\")\n",
    "    print(f\"[Filter] Kept: {len(kept)}\")\n",
    "    print(f\"[Filter] Dropped: {len(filtered_out)}\")\n",
    "    if filtered_out:\n",
    "        print(\"[Filter] Dropped (id  observed_len  expected_len  reasons) — first 20:\")\n",
    "        for sid, ol, el, reason in filtered_out[:20]:\n",
    "            print(f\"  {sid}\\t{ol}\\t{el}\\t{reason}\")\n",
    "        if len(filtered_out) > 20:\n",
    "            print(f\"  ... ({len(filtered_out) - 20} more)\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filter_report_path = output_dir / \"_filter_report.tsv\"\n",
    "    with open(filter_report_path, \"w\", newline=\"\") as fh:\n",
    "        w = csv.writer(fh, delimiter=\"\\t\")\n",
    "        w.writerow([\"sequence_id\", \"observed_length\", \"expected_length\", \"reasons\"])\n",
    "        for sid, ol, el, reason in filtered_out:\n",
    "            w.writerow([sid, ol, el, reason])\n",
    "    print(f\"[Filter] Report written: {filter_report_path}\")\n",
    "\n",
    "    if WRITE_FILTERED_MSA:\n",
    "        filtered_msa_path = output_dir / f\"{msa_path.stem}.len{expected_len}.filtered.fa\"\n",
    "        write_simple_fasta(kept, filtered_msa_path)\n",
    "        print(f\"[Filter] Filtered MSA written: {filtered_msa_path}\")\n",
    "\n",
    "    if not kept:\n",
    "        raise RuntimeError(\"No sequences remain after filtering; aborting.\")\n",
    "\n",
    "    # Build position→column mapping\n",
    "    ref_idx = find_reference_row(kept, accession)\n",
    "    if ref_idx is not None:\n",
    "        pos_to_col = build_pos_to_col_map_from_reference(kept[ref_idx][1])\n",
    "    else:\n",
    "        if alignment_has_any_gaps(kept):\n",
    "            raise RuntimeError(\n",
    "                \"No row containing the accession found and gaps detected in remaining alignment; \"\n",
    "                \"cannot safely map genome positions to alignment columns.\\n\"\n",
    "                f\"Either include a reference row for {accession} in the MSA or ensure the alignment is ungapped.\"\n",
    "            )\n",
    "        pos_to_col = build_pos_to_col_map_identity(expected_len)\n",
    "\n",
    "    # Extract features & write outputs (using kept sequences)\n",
    "    features = extract_features(record, level=feature_level)\n",
    "    index_rows = []\n",
    "    for feat in features:\n",
    "        try:\n",
    "            cols = collect_columns_for_feature(pos_to_col, feat, revcomp_neg=revcomp_neg)\n",
    "        except KeyError as ke:\n",
    "            print(f\"Skipping feature {feat.name}: {ke}\")\n",
    "            continue\n",
    "\n",
    "        # Optionally trim trailing stop codon for CDS features, based on the reference CDS\n",
    "        trimmed = False\n",
    "        if TRIM_TRAILING_STOP and feat.kind == \"CDS\":\n",
    "            ref_cds = feature_ref_coding_seq(record, feat, revcomp_neg=revcomp_neg)\n",
    "            if len(ref_cds) >= 3 and ref_cds[-3:] in STOP_CODONS:\n",
    "                cols = cols[:-3]\n",
    "                trimmed = True\n",
    "\n",
    "        sliced = slice_alignment_columns(kept, cols, feat, revcomp_neg=revcomp_neg)\n",
    "        start, end = feat.intervals[0][0], feat.intervals[-1][1]\n",
    "        suffix_parts = [f\"{feat.kind}={feat.name}\", f\"strand={feat.strand}\", f\"coord={start}-{end}\"]\n",
    "        if trimmed:\n",
    "            suffix_parts.append(\"trimmed_stop=1\")\n",
    "        suffix = \";\".join(suffix_parts)\n",
    "        out_name = f\"{sanitize_name(feat.kind)}__{sanitize_name(feat.name)}__{start}_{end}.fa\"\n",
    "        out_path = output_dir / out_name\n",
    "        write_fasta(sliced, out_path, header_suffix=suffix)\n",
    "        index_rows.append({\n",
    "            \"name\": feat.name,\n",
    "            \"kind\": feat.kind,\n",
    "            \"strand\": feat.strand,\n",
    "            \"intervals\": \";\".join([f\"{s}-{e}\" for s, e in feat.intervals]),\n",
    "            \"trimmed_stop\": int(trimmed),\n",
    "            \"output_fasta\": str(out_path),\n",
    "        })\n",
    "\n",
    "    idx_path = output_dir / \"_index.tsv\"\n",
    "    with open(idx_path, \"w\", newline=\"\") as fh:\n",
    "        w = csv.DictWriter(\n",
    "            fh,\n",
    "            fieldnames=[\"name\", \"kind\", \"strand\", \"intervals\", \"trimmed_stop\", \"output_fasta\"],\n",
    "            delimiter=\"\\t\"\n",
    "        )\n",
    "        w.writeheader()\n",
    "        for row in index_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "    print(f\"Wrote {len(index_rows)} feature-alignments to {output_dir}\")\n",
    "    print(f\"Index: {idx_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211493e-722d-4c91-bf4e-41cc62b44e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
